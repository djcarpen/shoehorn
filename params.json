{
  "name": "Shoehorn",
  "tagline": "How to create Hive UDF in Scala",
  "body": "# Abstract\r\nThere are many articles on how to extend the capabilities of Apache Hive with the use of custom UDFs (User Defined Functions). This article will focus on how to create a UDF in the Scala programming language. Once we create the UDF, we will test it on the Hortonworks Sandbox 2.4.\r\n\r\n## Environment\r\nIntellij IDEA 2016\r\nOracle Virtual Box\r\nHortonworks Sandbox 2.4\r\n\r\n### Let's get started...\r\nThe first thing we need to do is create a Scala class. First we need to import the appropriate Apache Hive libraries.\r\n    `import org.apache.hadoop.hive.ql.exec.UDF`\r\n\r\nOur class will extend the imported Hive library. For this example, the class name is ScalaUDF. \r\n    `class ScalaUDF extends UDF {\r\n}`\r\n\r\nNow we add our function definition. For this example, I'm creating a simple function that takes an input column of string type and returns the length of that string. This function is for demonstration purposes only as there is already a Hive function that provides the same functionality. \r\n    `def evaluate(str: String): Int = {\r\n    str.length()\r\n  }`\r\n\r\nThe final class definition:\r\n    `class ScalaUDF extends UDF {\r\n  def evaluate(str: String): Int = {\r\n    str.length()\r\n  }\r\n}`",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}