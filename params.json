{
  "name": "Shoehorn",
  "tagline": "How to create Hive UDF in Scala",
  "body": "### Abstract\r\nThere are many articles on how to extend the capabilities of Apache Hive with the use of custom UDFs (User Defined Functions). This article will focus on how to create a UDF in the Scala programming language. Once we create the UDF, we will test it on the Hortonworks Sandbox 2.4.\r\n\r\n### Environment\r\n- Intellij IDEA 2016\r\n- Oracle Virtual Box\r\n- Hortonworks Sandbox 2.4\r\n\r\n### Let's get started...\r\nThe first thing we need to do is create a Scala class. For this example, the class name is ScalaUDF. \r\n\r\n```\r\nclass ScalaUDF {\r\n}\r\n```\r\n\r\nThe next step is to edit your project structure and add the [hive-exec-1.2.1.jar](http://repo1.maven.org/maven2/org/apache/hive/hive-exec/1.2.1/hive-exec-1.2.1.jar) file to the module dependencies.\r\n\r\nWe can now reference that library in our ScalaUDF class.\r\n\r\n```\r\nimport org.apache.hadoop.hive.ql.exec.UDF\r\n```\r\n\r\n\r\n\r\n\r\n\r\nNow we add our function definition. For this example, I'm creating a simple function that takes an input column of string type and returns the length of that string. This function is for demonstration purposes only as there is already a Hive function that provides the same functionality. \r\n\r\n```\r\ndef evaluate(str: String): Int = {\r\nstr.length()\r\n}\r\n```\r\n\r\n\r\nScalaUDF class definition:\r\n```\r\nclass ScalaUDF {\r\n  def evaluate(str: String): Int = {\r\n    str.length()\r\n  }\r\n}\r\n```\r\n\r\n### Set dependencies\r\nIn order to use our function in Hive, we need to use the\r\n\r\n\r\n### Creating the jar file\r\nNow that we have our class created, we need to package it into a jar file. Edit the \r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}