{
  "name": "Shoehorn",
  "tagline": "How to create Hive UDF in Scala",
  "body": "### Abstract\r\nThere are many articles on how to extend the capabilities of Apache Hive with the use of custom UDFs (User Defined Functions) written in java. This article will focus on how to create a UDF in the Scala programming language. Once we create the UDF, we will test it on the Hortonworks Sandbox 2.4.\r\n\r\n### Environment\r\n- Intellij IDEA 2016\r\n- Oracle Virtual Box\r\n- Hortonworks Sandbox 2.4\r\n\r\n### Artifact produced\r\n- shoehorn.jar\r\n\r\n### Create project.\r\nUsing Intellij IDEA, create a new project with the following configuration.\r\n- Project type: Scala\r\n- Project name: shoehorn\r\n- Project SDK: 1.8 (java version 1.8)\r\n- Scala SDK: scala-sdk-2.11.8\r\n\r\n\r\n------------ | -------------\r\nProject type | Scala\r\nProject name | shoehorn\r\nProject SDK | 1.8 (java version 1.8)\r\nScala SDK | scala-sdk-2.11.8\r\n\r\n### Create package\r\nOnce the project is created, add a package under /shoehorn/src/ named: udf\r\n\r\n### Set dependencies\r\nEdit your project structure and add the [hive-exec-1.2.1.jar](http://repo1.maven.org/maven2/org/apache/hive/hive-exec/1.2.1/hive-exec-1.2.1.jar) file to the module dependencies.\r\n\r\n\r\n### Create Artifact\r\nEdit your project structure and add and artifact of type JAR>module with dependencies. For this example, I am adding the artifact to the shoehorn module.\r\n\r\n\r\n### Create Scala class\r\nThe first thing we need to do is create a Scala class referencing the org.apache.hadoop.hive.ql.exec.UDF library. For this example, the class name is ScalaUDF. \r\n\r\n\r\n```\r\npackage udf\r\n\r\nimport org.apache.hadoop.hive.ql.exec.UDF\r\n\r\nclass ScalaUDF extends UDF {\r\n}\r\n```\r\n\r\n\r\n### Define function\r\nNow we add our function definition inside the ScalaUDF definition. For this example, I'm creating a simple function that takes an input column of string type and returns the length of that string. This function is for demonstration purposes only as there is already a Hive function that provides the same functionality. \r\n\r\n```\r\npackage udf\r\n\r\nimport org.apache.hadoop.hive.ql.exec.UDF\r\n\r\nclass ScalaUDF extends UDF {\r\n  def evaluate(str: String): Int = {\r\n    str.length()\r\n  }\r\n}\r\n```\r\n\r\n\r\n### Create artifact\r\nUsing Intellij IDEA select Build>\"Make Project\" from the file menu. Next, select Build>\"Build Artifacts...\". This will create the /shoehorn/out/artifacts/shoehorn_jar/shoehorn.jar file.\r\n\r\n\r\n### Create Hive UDF\r\nUpload the shoehorn.jar file to HDFS. You may need to change the file permissions depending on which user will be executing Hive commands. For this example, I've uploaded the file to my local Hortonworks Sandbox in the location: hdfs:///jars/shoehorn.jar\r\n\r\nIn hive, run the following command to register a new udf. Note: This can be done in the Hive view in Ambari or through the Hive CLI.\r\n\r\n```\r\ncreate function getScalaLength as 'udf.ScalaUDF' using jar 'hdfs:///jars/shoehorn.jar';\r\n```\r\n\r\nFinally, we can test our udf using the following HQL in Hive.\r\n\r\n```\r\nselect phone_number, getScalaLength(phone_number) from xademo.customer_details limit 5;\r\n```\r\n\r\nThe result set returned:\r\n\r\n```\r\nPHONE_NUM\t9\r\n5553947406\t10\r\n7622112093\t10\r\n5092111043\t10\r\n9392254909\t10\r\nTime taken: 6.38 seconds, Fetched: 5 row(s)\r\n```\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}